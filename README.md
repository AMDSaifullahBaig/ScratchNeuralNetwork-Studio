# Modular Neural Network Engine
**Author:** MD Saifullah Baig.A  
**Version:** 2.0  
**Status:** Active

## ðŸ“Œ Overview
This repository contains a modular, scratch-built Deep Learning framework in Python. It is designed to demystify the internal mechanics of deep learning by implementing **Backpropagation**, **Optimizers (SGD, Adam)**, and **Dynamic Layer Stacking** entirely from scratch using NumPy, without relying on auto-differentiation libraries like PyTorch or TensorFlow.

## ðŸš€ Key Features
* **Modular Architecture:** Build networks by stacking layers dynamically (similar to Keras Sequential API).
* **Advanced Optimizers:** Custom implementation of **Adam** (Adaptive Moment Estimation) and **SGD** (Stochastic Gradient Descent).
* **Vectorized Operations:** High-performance matrix computations using NumPy.
* **Activation Functions:** Includes Sigmoid, Tanh, and ReLU with their respective derivatives.
* **Visualization:** Real-time tracking of training loss.

## ðŸ“‚ Project Structure
```text
Neural_Network_Scratch_App/
â”‚
â”œâ”€â”€ Neural_Network_Engine.py            # The Core Computation Library
â”œâ”€â”€ Neural_Network_Main.py              # Main Execution Script
â”œâ”€â”€ Neural_Network_Engine.ipynb         #Easy Reference material
â”œâ”€â”€ Neural_Network_Main.ipynb           #Easy Reference material
â”œâ”€â”€ requirements.txt                    # List of dependencies
â”œâ”€â”€ README.md                           # Project Documentation
â””â”€â”€ .gitignore                          # Ignored files (.venv, __pycache__)
```
## ðŸ’» Usage
To run the diabetes regression example:
```bash
python Neural_Network_Main.py 
```

> **Note:** Detailed installation and usage documentation is currently being written and will be updated shortly.